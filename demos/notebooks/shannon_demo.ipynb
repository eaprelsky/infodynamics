{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'Python 3.11.9' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'c:/Users/eaprelsky/AppData/Local/Microsoft/WindowsApps/python3.11.exe -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "# ðŸ“Š Shannon Information Theory: Academic Demonstration\n",
        "\n",
        "**From: Chapter 2 Literature Review - Shannon's Information Revolution (1948)**\n",
        "\n",
        "This notebook provides an interactive academic exploration of Shannon's foundational formula and its connection to information physics.\n",
        "\n",
        "## ðŸ“š Historical Context\n",
        "\n",
        "Claude Shannon's 1948 paper \"A Mathematical Theory of Communication\" {cite}`shannon1948mathematical` established the mathematical foundation for all subsequent information theory.\n",
        "\n",
        "## ðŸ§® Shannon's Information Formula\n",
        "\n",
        "Shannon defined the information content of an event as:\n",
        "\n",
        "$$I(x) = -\\log_2 p(x)$$\n",
        "\n",
        "where:\n",
        "- $I(x)$ = information content (in bits)\n",
        "- $p(x)$ = probability of event $x$\n",
        "- Base 2 logarithm gives units in bits\n",
        "\n",
        "### Mathematical Properties\n",
        "\n",
        "1. **Rare events carry more information:** As $p(x) \\rightarrow 0$, $I(x) \\rightarrow \\infty$\n",
        "2. **Certain events carry no information:** When $p(x) = 1$, $I(x) = 0$\n",
        "3. **Additive for independent events:** $I(x,y) = I(x) + I(y)$ if independent\n",
        "\n",
        "## ðŸ”— Connection to Information Physics\n",
        "\n",
        "Shannon's formula becomes the **surprise component** of information voltage:\n",
        "\n",
        "$$U_{\\text{surprise}} = -\\log_2 p(\\text{message})$$\n",
        "\n",
        "This directly implements Shannon's insight in our electrical framework.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Academic imports and setup\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from scipy import stats\n",
        "import seaborn as sns\n",
        "\n",
        "# Configure academic plotting style\n",
        "plt.style.use('seaborn-v0_8-paper')\n",
        "plt.rcParams.update({\n",
        "    'figure.figsize': (10, 6),\n",
        "    'font.size': 12,\n",
        "    'axes.labelsize': 14,\n",
        "    'axes.titlesize': 16,\n",
        "    'xtick.labelsize': 12,\n",
        "    'ytick.labelsize': 12,\n",
        "    'legend.fontsize': 12\n",
        "})\n",
        "\n",
        "def shannon_information(p):\n",
        "    \"\"\"\n",
        "    Calculate Shannon information content\n",
        "    \n",
        "    Parameters:\n",
        "    p : float or array\n",
        "        Probability values (0 < p <= 1)\n",
        "        \n",
        "    Returns:\n",
        "    float or array\n",
        "        Information content in bits\n",
        "        \n",
        "    References:\n",
        "    Shannon, C. E. (1948). A mathematical theory of communication. \n",
        "    The Bell System Technical Journal, 27(3), 379-423.\n",
        "    \"\"\"\n",
        "    return -np.log2(p)\n",
        "\n",
        "print(\"ðŸ“š Shannon Information Theory - Academic Implementation\")\n",
        "print(\"âœ… Libraries loaded and academic plotting configured\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Academic Figure 1: Shannon Information vs Probability\n",
        "# Reproducing key insights from Shannon (1948)\n",
        "\n",
        "# Generate probability range\n",
        "probabilities = np.linspace(0.001, 1.0, 1000)\n",
        "information_content = shannon_information(probabilities)\n",
        "\n",
        "# Create academic-quality figure\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "# Main relationship plot\n",
        "ax1.plot(probabilities, information_content, 'navy', linewidth=2.5, label='I(x) = -logâ‚‚(p(x))')\n",
        "ax1.set_xlabel('Probability p(x)')\n",
        "ax1.set_ylabel('Information Content I(x) [bits]')\n",
        "ax1.set_title('Shannon Information Function\\n(Shannon, 1948)')\n",
        "ax1.grid(True, alpha=0.3)\n",
        "ax1.legend()\n",
        "\n",
        "# Key points annotation\n",
        "key_points = [(0.001, shannon_information(0.001)), \n",
        "              (0.1, shannon_information(0.1)),\n",
        "              (0.5, shannon_information(0.5)),\n",
        "              (1.0, shannon_information(1.0))]\n",
        "\n",
        "for p, i in key_points:\n",
        "    ax1.plot(p, i, 'ro', markersize=8)\n",
        "    ax1.annotate(f'p={p:.3f}\\nI={i:.1f} bits', \n",
        "                xy=(p, i), xytext=(p+0.1, i+1),\n",
        "                fontsize=10, ha='left',\n",
        "                arrowprops=dict(arrowstyle='->', color='red', alpha=0.7))\n",
        "\n",
        "# Examples with real-world context\n",
        "examples = pd.DataFrame({\n",
        "    'Event': ['Coin flip (heads)', 'Die roll (6)', 'Lottery win', 'Sunrise tomorrow', 'Random word'],\n",
        "    'Probability': [0.5, 1/6, 1e-8, 0.999, 1/50000],\n",
        "    'Context': ['Fair coin', '6-sided die', '1 in 100M', 'Very likely', 'English vocabulary']\n",
        "})\n",
        "\n",
        "examples['Information'] = shannon_information(examples['Probability'])\n",
        "\n",
        "# Bar chart of examples\n",
        "ax2.bar(range(len(examples)), examples['Information'], color='steelblue', alpha=0.7)\n",
        "ax2.set_xticks(range(len(examples)))\n",
        "ax2.set_xticklabels(examples['Event'], rotation=45, ha='right')\n",
        "ax2.set_ylabel('Information Content [bits]')\n",
        "ax2.set_title('Real-World Examples\\nShannon Information Content')\n",
        "\n",
        "# Add value labels\n",
        "for i, (idx, row) in enumerate(examples.iterrows()):\n",
        "    ax2.text(i, row['Information'] + 0.5, f'{row[\"Information\"]:.1f}', \n",
        "            ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Academic summary table\n",
        "print(\"ðŸ“Š TABLE 1: Shannon Information Content for Real-World Events\")\n",
        "print(\"=\"*70)\n",
        "display(examples[['Event', 'Probability', 'Information', 'Context']])\n",
        "\n",
        "print(f\"\\nðŸ“ˆ KEY INSIGHT: Information content varies from {examples['Information'].min():.1f} to {examples['Information'].max():.1f} bits\")\n",
        "print(\"ðŸ’¡ This 26-bit range demonstrates the enormous variation in cognitive 'voltage' across different messages.\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
